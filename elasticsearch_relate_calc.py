import requests
import json
from requests.auth import HTTPBasicAuth

# âœ… Elasticsearchè¨­å®š
ES_URL = 'https://localhost:9200'
INDEX_NAME = 'obsidian_notes'
USERNAME = 'elastic'
PASSWORD = 'elastic'

# ğŸ”’ è¨¼æ˜æ›¸ã‚¨ãƒ©ãƒ¼ç„¡è¦–ï¼ˆè‡ªå·±ç½²åè¨¼æ˜æ›¸å¯¾ç­–ï¼‰
verify_ssl = False

# âœ… å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—
def fetch_all_docs():
    query = {
        "size": 10000,
        "_source": ["_id"]
    }
    response = requests.get(
        f'{ES_URL}/{INDEX_NAME}/_search',
        headers={"Content-Type": "application/json"},
        auth=HTTPBasicAuth(USERNAME, PASSWORD),
        verify=verify_ssl,
        data=json.dumps(query)
    )
    data = response.json()
    return [hit['_id'] for hit in data['hits']['hits']]

# âœ… more_like_this å®Ÿè¡Œ
def fetch_similar_docs(doc_id, min_score=0.1, max_results=10):  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ä¸Šä½10ä»¶ã«åˆ¶é™
    query = {
        "size": max_results,  # çµæœã®ä»¶æ•°ã‚’åˆ¶é™
        "query": {
            "more_like_this": {
                "fields": [
                    "title^2",      # ã‚¿ã‚¤ãƒˆãƒ«ã¯2å€ã®é‡ã¿
                    "tags^3",       # ã‚¿ã‚°ã¯3å€ã®é‡ã¿ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦é‡è¦ï¼‰
                    "sections",     # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ§‹é€ 
                    "plain_text"    # æœ¬æ–‡
                ],
                "like": [{"_index": INDEX_NAME, "_id": doc_id}],
                "min_term_freq": 1,
                "min_doc_freq": 1
            }
        }
    }
    response = requests.post(
        f'{ES_URL}/{INDEX_NAME}/_search',
        headers={"Content-Type": "application/json"},
        auth=HTTPBasicAuth(USERNAME, PASSWORD),
        verify=verify_ssl,
        data=json.dumps(query)
    )
    data = response.json()
    # ã‚¹ã‚³ã‚¢æƒ…å ±ã‚’å«ã‚ã¦è¿”ã™
    return [(hit['_id'], hit['_score']) for hit in data['hits']['hits'] if hit['_id'] != doc_id and hit['_score'] >= min_score]

# âœ… Obsidianãƒªãƒ³ã‚¯å½¢å¼ã‚’ä½œã‚‹
def to_obsidian_links(similar_docs):
    return ' '.join([f'[[{doc_id}]]' for doc_id, _ in similar_docs])

# âœ… æ›´æ–°ç”¨API
def update_doc_with_links(doc_id, links):
    payload = {
        "doc": {
            "related_links": links  # ğŸ”„ ä¿å­˜å…ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‚’å¤‰æ›´ã™ã‚‹å ´åˆã¯ã“ã“
        }
    }
    response = requests.post(
        f'{ES_URL}/{INDEX_NAME}/_update/{doc_id}',
        headers={"Content-Type": "application/json"},
        auth=HTTPBasicAuth(USERNAME, PASSWORD),
        verify=verify_ssl,
        data=json.dumps(payload)
    )
    return response.json()

# âœ… å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
if __name__ == '__main__':
    doc_ids = fetch_all_docs()
    print(f'Found {len(doc_ids)} documents.')

    for doc_id in doc_ids:
        print(f'Processing doc_id: {doc_id}')
        similar_docs = fetch_similar_docs(doc_id)
        # ã‚¹ã‚³ã‚¢æƒ…å ±ã‚’è¡¨ç¤ºï¼ˆé †ä½ä»˜ãï¼‰
        print('  Similar documents with scores (ranked by relevance):')
        for rank, (similar_id, score) in enumerate(similar_docs, 1):
            print(f'    {rank}. {similar_id}: {score:.3f}')
        links = to_obsidian_links(similar_docs)
        print(f'  Found {len(similar_docs)} related docs.')
        result = update_doc_with_links(doc_id, links)
        print(f'  Updated doc_id {doc_id}: {result}')
